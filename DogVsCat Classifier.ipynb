{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog vs Cat Convolution Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Python documentation found for 'tensorflow'.\n",
      "Use help() to get the interactive help utility.\n",
      "Use help(str) for help on the str class.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help('tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flatten\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Parameter:\n",
    "* Rectifier Linear Unit \n",
    "* Adam optimizer\n",
    "* Sigmoid on Final output\n",
    "* Binary CrossEntropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      8\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m adam \u001b[38;5;241m=\u001b[39m \u001b[43mtensorflow\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, amsgrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m classifier\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),strides=2)) #if stride not given it equal to pool filter size\n",
    "classifier.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))\n",
    "adam = tensorflow.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "classifier.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Training Set\n",
    "train_set = train_datagen.flow_from_directory('train',\n",
    "                                             target_size=(64,64),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary')\n",
    "#Validation Set\n",
    "test_set = test_datagen.flow_from_directory('test',\n",
    "                                           target_size=(64,64),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode='binary',\n",
    "                                           shuffle=False)\n",
    "#Test Set /no output available\n",
    "test_set1 = test_datagen.flow_from_directory('test1',\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier.fit_generator(train_set,\n",
    "                        steps_per_epoch=800, \n",
    "                        epochs = 200,\n",
    "                        validation_data = test_set,\n",
    "                        validation_steps = 20, \n",
    "                        #callbacks=[tensorboard]\n",
    "                        );\n",
    "\n",
    "#Some Helpful Instructions:\n",
    "\n",
    "#finetune you network parameter in last by using low learning rate like 0.00001\n",
    "#classifier.save('resources/dogcat_model_bak.h5')\n",
    "#from tensorflow.keras.models import load_model\n",
    "#model = load_model('partial_trained1')\n",
    "#100 iteration with learning rate 0.001 and after that 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "classifier = load_model('resources/dogcat_model_bak.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of image\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "img1 = image.load_img('test/Cat/10.jpg', target_size=(64, 64))\n",
    "img = image.img_to_array(img1)\n",
    "img = img/255\n",
    "# create a batch of size 1 [N,H,W,C]\n",
    "img = np.expand_dims(img, axis=0)\n",
    "prediction = classifier.predict(img, batch_size=None,steps=1) #gives all class prob.\n",
    "if(prediction[:,:]>0.5):\n",
    "    value ='Dog :%1.2f'%(prediction[0,0])\n",
    "    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))\n",
    "else:\n",
    "    value ='Cat :%1.2f'%(1.0-prediction[0,0])\n",
    "    plt.text(20, 62,value,color='red',fontsize=18,bbox=dict(facecolor='white',alpha=0.8))\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_set.reset\n",
    "ytesthat = classifier.predict_generator(test_set)\n",
    "df = pd.DataFrame({\n",
    "    'filename':test_set.filenames,\n",
    "    'predict':ytesthat[:,0],\n",
    "    'y':test_set.classes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "df['y_pred'] = df['predict']>0.5\n",
    "df.y_pred = df.y_pred.astype(int)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = df[df['y']!=df['y_pred']]\n",
    "print('Total misclassified image from 5000 Validation images : %d'%misclassified['y'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of test set\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(df.y,df.y_pred)\n",
    "sns.heatmap(conf_matrix,cmap=\"YlGnBu\",annot=True,fmt='g');\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of Cat image misclassified as Dog.\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "CatasDog = df['filename'][(df.y==0)&(df.y_pred==1)]\n",
    "fig=plt.figure(figsize=(15, 6))\n",
    "columns = 7\n",
    "rows = 3\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    img = image.load_img('test/'+CatasDog.iloc[i], target_size=(64, 64))\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of Dog image misclassified as Cat.\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "DogasCat = df['filename'][(df.y==1)&(df.y_pred==0)]\n",
    "fig=plt.figure(figsize=(15, 6))\n",
    "columns = 7\n",
    "rows = 3\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    img = image.load_img('test/'+DogasCat.iloc[i], target_size=(64, 64))\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Layers Ouptut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Image for Layer visualization\n",
    "img1 = image.load_img('test/Cat/14.jpg')\n",
    "plt.imshow(img1);\n",
    "#preprocess image\n",
    "img1 = image.load_img('test/Cat/14.jpg', target_size=(64, 64))\n",
    "img = image.img_to_array(img1)\n",
    "img = img/255\n",
    "img = np.expand_dims(img, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = [ layer.name for layer in classifier.layers]\n",
    "print('layer name : ',model_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "conv2d_6_output = Model(inputs=classifier.input, outputs=classifier.get_layer('conv2d_6').output)\n",
    "conv2d_7_output = Model(inputs=classifier.input,outputs=classifier.get_layer('conv2d_7').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_6_features = conv2d_6_output.predict(img)\n",
    "conv2d_7_features = conv2d_7_output.predict(img)\n",
    "print('First conv layer feature output shape : ',conv2d_6_features.shape)\n",
    "print('First conv layer feature output shape : ',conv2d_7_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Convolution Filter Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conv2d_6_features[0, :, :, 4], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Covolution Layer Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_6_features[0, :, :, i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Covolution Layer Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14,7))\n",
    "columns = 8\n",
    "rows = 4\n",
    "for i in range(columns*rows):\n",
    "    #img = mpimg.imread()\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title('filter'+str(i))\n",
    "    plt.imshow(conv2d_7_features[0, :, :, i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generator image set u can use \n",
    "# ypred = classifier.predict_generator(test_set)\n",
    "\n",
    "fig=plt.figure(figsize=(15, 6))\n",
    "columns = 7\n",
    "rows = 3\n",
    "for i in range(columns*rows):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img1 = image.load_img('test1/'+test_set1.filenames[np.random.choice(range(12500))], target_size=(64, 64))\n",
    "    img = image.img_to_array(img1)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediction = classifier.predict(img, batch_size=None,steps=1) #gives all class prob.\n",
    "    if(prediction[:,:]>0.5):\n",
    "        value ='Dog :%1.2f'%(prediction[0,0])\n",
    "        plt.text(20, 58,value,color='red',fontsize=10,bbox=dict(facecolor='white',alpha=0.8))\n",
    "    else:\n",
    "        value ='Cat :%1.2f'%(1.0-prediction[0,0])\n",
    "        plt.text(20, 58,value,color='red',fontsize=10,bbox=dict(facecolor='white',alpha=0.8))\n",
    "    plt.imshow(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Model Accuracy\n",
    "x1 = classifier.evaluate_generator(train_set)\n",
    "x2 = classifier.evaluate_generator(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy  : %1.2f%%     Training loss  : %1.6f'%(x1[1]*100,x1[0]))\n",
    "print('Validation Accuracy: %1.2f%%     Validation loss: %1.6f'%(x2[1]*100,x2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The Architecture and parameter used in this network are capable of producing accuracy of **97.56%** on Validation Data which is pretty good. It is possible to Achieve more accuracy on this dataset using deeper network and fine tuning of network parameters for training. You can download this trained model from resource directory and Play with it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
